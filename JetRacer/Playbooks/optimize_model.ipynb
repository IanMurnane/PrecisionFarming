{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5pk4SL9Z5JyR"
      },
      "source": [
        "# Optimize model with TensorRT\n",
        "\n",
        "First, create the model. This must match the model used in the [interactive training notebook (`interactive_regression.ipynb`)](./interactive_regression.ipynb)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorrt==8.5.3.1\n",
        "!git clone https://github.com/NVIDIA-AI-IOT/torch2trt\n",
        "!cd torch2trt && python3 setup.py install\n",
        "# restart the runtime after this"
      ],
      "metadata": {
        "id": "LbjBzSqx57z-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "C2SHJzJw5Lsw",
        "outputId": "37fd0ccb-2fea-4f43-a0b5-972c580c121e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "tags": [],
        "id": "UGu7fQDL5JyZ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "\n",
        "CATEGORIES = ['apex']\n",
        "\n",
        "device = torch.device('cuda')\n",
        "model = torchvision.models.resnet18(pretrained=False)\n",
        "model.fc = torch.nn.Linear(512, 2 * len(CATEGORIES))\n",
        "model = model.cuda().eval().half()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GQW9VM15Jyc"
      },
      "source": [
        "Next, load the saved model.  Enter the model path you used to save."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "0KFi8fFr5Jye",
        "outputId": "448bfc01-1846-4db4-f1d9-d4c64829424c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "model.load_state_dict(torch.load('/content/drive/MyDrive/Colab Notebooks/resnet18-11epochs-v5.pth'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YgI-Xlb75Jye"
      },
      "source": [
        "Convert and optimize the model using ``torch2trt`` for faster inference with TensorRT.  Please see the [torch2trt](https://github.com/NVIDIA-AI-IOT/torch2trt) readme for more details.\n",
        "\n",
        "> This optimization process can take a couple minutes to complete."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "tags": [],
        "id": "KmUJS3D85Jyf"
      },
      "outputs": [],
      "source": [
        "from torch2trt import torch2trt\n",
        "\n",
        "data = torch.zeros((1, 3, 224, 224)).cuda().half()\n",
        "\n",
        "model_trt = torch2trt(model, [data], fp16_mode=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTuSVmAS5Jyh"
      },
      "source": [
        "Save the optimized model using the cell below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "i4OSK2ra5Jyh"
      },
      "outputs": [],
      "source": [
        "torch.save(model_trt.state_dict(), 'resnet18-11epochs-v5-optimised.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8sdeZ8VC5Jyj"
      },
      "source": [
        "# Run the optimized model\n",
        "\n",
        "Move to [the final notebook](road_following.ipynb) to load the optimized model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jyugX6AI5Jyk"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}